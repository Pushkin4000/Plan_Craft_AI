{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "171c7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GROQ_API_KEY=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02441d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm=ChatGroq(model=\"openai/gpt-oss-120b\",temperature=0.6,reasoning_format=\"hidden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c092bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pushkin\\AppData\\Local\\Temp\\ipykernel_12668\\3002614440.py:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  proj_chain= LLMChain(llm=llm,prompt=Poxs)\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "Poxs=PromptTemplate(\n",
    "    input_variable=[\"Technology\"],\n",
    "    template=\"Reply with only one word answer: Tell me a project name regarding {Technology}.\"\n",
    ")\n",
    "\n",
    "proj_chain= LLMChain(llm=llm,prompt=Poxs)\n",
    "\n",
    "\n",
    "Poxs2=PromptTemplate(\n",
    "    input_variable=[\"project_name\"],\n",
    "    template=\"Generate me steps to perform this {project_name} in a comma seperated list\"\n",
    ")\n",
    "\n",
    "proj_full=LLMChain(llm=llm,prompt=Poxs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c89b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pushkin\\AppData\\Local\\Temp\\ipykernel_12668\\504380394.py:3: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(\"Yolo\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Install Python\\u202f3.8+ and create a virtual environment,Activate the virtual environment and upgrade pip,Install PyTorch compatible with your CUDA version (e.g., `pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118`),Install required packages: `pip install -U cython numpy opencv-python tqdm pycocotools`,Clone the YOLOX repository: `git clone https://github.com/Megvii-BaseDetection/YOLOX.git && cd YOLOX`,Install YOLOX in editable mode: `pip install -v -e .`,Prepare your dataset in COCO format (images folder, annotations JSON),Create a data configuration file under `datasets/` pointing to your dataset paths,Modify the model configuration (e.g., `yolox_s`, `yolox_m`) in `exps/` to match your number of classes and input size,Run the training script with desired parameters: `python tools/train.py -f exps/default/yolox_s.py -c yolox_s.pth --batch-size 16 --device 0 --epochs 300`,Monitor training progress via TensorBoard or the printed logs,After training, evaluate the model: `python tools/eval.py -f exps/default/yolox_s.py -c path/to/your/best_ckpt.pth --device 0 --conf 0.001 --nms 0.65`,Export the trained model to ONNX (optional): `python tools/export_onnx.py -f exps/default/yolox_s.py -c path/to/your/best_ckpt.pth --output-name yolox_s.onnx`,Run inference on new images or video: `python tools/demo.py image -f exps/default/yolox_s.py -c path/to/your/best_ckpt.pth --path path/to/image.jpg --conf 0.25 --nms 0.45`,Fineâ€‘tune hyperparameters or perform further training as needed.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.chains import SimpleSequentialChain\n",
    "# chain=SimpleSequentialChain(chains=[proj_chain, proj_full])\n",
    "# chain.run(\"Yolo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f53b3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "Poxs=PromptTemplate(\n",
    "    input_variable=[\"Technology\"],\n",
    "    template=\"Reply with only one word answer: Tell me a project name regarding {Technology}.\"\n",
    ")\n",
    "\n",
    "proj_chain= LLMChain(llm=llm,prompt=Poxs,output_key=\"project_name\")\n",
    "\n",
    "\n",
    "Poxs2=PromptTemplate(\n",
    "    input_variable=[\"project_name\"],\n",
    "    template=\"Generate me steps to perform this {project_name} in a comma seperated list\"\n",
    ")\n",
    "\n",
    "proj_full=LLMChain(llm=llm,prompt=Poxs2,output_key=\"Procedure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f201e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pushkin\\AppData\\Local\\Temp\\ipykernel_14076\\2172223263.py:9: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain(\"LSTM\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Technology': 'LSTM',\n",
       " 'project_name': 'LSTMAnalyzer',\n",
       " 'Procedure': \"Sure! Here's a comma-separated list of steps to perform an LSTM analysis using LSTMAnalyzer:\\n\\n1. Install the LSTMAnalyzer library,  \\n2. Import the necessary libraries (e.g., LSTMAnalyzer, pandas, numpy, etc.),  \\n3. Load and preprocess your dataset,  \\n4. Split the data into training and testing sets,  \\n5. Build and train your LSTM model,  \\n6. Use LSTMAnalyzer to generate explanations for your LSTM model's predictions,  \\n7. Analyze feature importance using the analyzer,  \\n8. Extract and visualize temporal patterns from the model,  \\n9. Generate and review attention weights for sequence data,  \\n10. Save the analysis results for further review or reporting.  \\n\\nLet me know if you'd like more detailed instructions!\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains =[proj_chain,proj_full],\n",
    "    input_variables=[\"Technology\"],\n",
    "    output_variables=[\"project_name\",\"Procedure\"]\n",
    ")\n",
    "\n",
    "chain(\"LSTM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
